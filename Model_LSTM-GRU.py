import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import squarify
import random
import base64
from datetime import datetime, timedelta

from tensorflow.keras import backend as K
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU
from tensorflow.keras.optimizers import Adam
from vnstock import Vnstock

st.set_page_config(
    page_title="Applying deep learning to portfolio optimization in the Vietnamese stock market", 
    page_icon="üìä"
)

# V√¨ Streamlit d√πng c∆° ch·∫ø v·∫Ω inline, ta chuy·ªÉn backend c·ªßa matplotlib
plt.switch_backend('Agg')

#========================
# 0) (Tu·ª≥ ch·ªçn) C·ªë ƒë·ªãnh random seed ƒë·ªÉ so s√°nh ch·∫∑t h∆°n
#========================
SEED_VALUE = 42
random.seed(SEED_VALUE)
np.random.seed(SEED_VALUE)
tf.random.set_seed(SEED_VALUE)

#========================
# T·∫Øt c·∫£nh b√°o
#========================
import warnings
warnings.filterwarnings('ignore')

#========================
# 1) ƒê·ªäNH NGHƒ®A C√ÅC H√ÄM, M√î H√åNH
#========================

def add_bg_from_local(image_file):
    
    with open(image_file, "rb") as image_file_obj:
        encoded_string = base64.b64encode(image_file_obj.read())
    st.markdown(
    f"""
    <style>
    .stApp {{
        background-image: url(data:image/png;base64,{encoded_string.decode()}); 
        background-size: cover; 
        background-color: rgba(255, 255, 255, 0.8); 
        background-blend-mode: overlay; 
    }}
    .custom-title {{
        color: #F05454;
    }}
    .stMarkdown, .stText {{
        color: #30475E !important;
    }}
    </style>
    """,
    unsafe_allow_html=True
    )

add_bg_from_local('background.png')

#========================
# Hi·ªÉn th·ªã logo v√† ti√™u ƒë·ªÅ
#========================
col_logo, col_title = st.columns([1, 4])
with col_logo:
    st.image("Logo_HUB.png", width=400)
with col_title:
    st.markdown(
        """
        <h1 style="color: #0B5394; text-align: center; font-size: 32px;">TR∆Ø·ªúNG ƒê·∫†I H·ªåC NG√ÇN H√ÄNG TH√ÄNH PH·ªê H·ªí CH√ç MINH</h1>
        """,
        unsafe_allow_html=True
    )
st.markdown(
    """
    <h2 style="color: #333; text-align: center; font-size: 40px; margin-top: 10px;">
        X√¢y d·ª±ng danh m·ª•c ƒë·∫ßu t∆∞ t·ªëi ∆∞u b·∫±ng m√¥ h√¨nh LSTM - GRU
    </h2>
    """,
    unsafe_allow_html=True
)

#========================
# C√°c h√†m l·∫•y d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh
#========================

def fetch_stock_data(ticker, start_date, end_date):
    """T·∫£i d·ªØ li·ªáu gi√° ƒë√≥ng c·ª≠a, tr·∫£ v·ªÅ DataFrame g·ªìm c·ªôt 'close' v√† index='time'."""
    try:
        dt = Vnstock().stock(symbol=ticker, source='VCI').quote.history(
            start=start_date, 
            end=end_date
        )
        dt['time'] = pd.to_datetime(dt['time'])
        dt.set_index('time', inplace=True)
        dt = dt[['close']].copy()
        dt['ticker'] = ticker
        return dt
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu cho {ticker}: {e}")
        return None

class SharpeLossModel:
    def __init__(self, data):
        # data shape (T, n_assets)
        self.data = tf.constant(data.values, dtype=tf.float32)

    def sharpe_loss(self, _, y_pred):
        """M·∫•t m√°t = -Sharpe => m·ª•c ti√™u l√† t·ªëi ƒëa h√≥a Sharpe Ratio."""
        data_normalized = self.data / (self.data[0] + K.epsilon())
        portfolio_values = tf.reduce_sum(data_normalized * y_pred[0], axis=1)
        pvals_shift = portfolio_values[:-1]
        pvals_curr  = portfolio_values[1:]
        daily_ret = (pvals_curr - pvals_shift) / (pvals_shift + K.epsilon())

        mean_r = K.mean(daily_ret)
        std_r  = K.std(daily_ret) + K.epsilon()

        rf = 0.016
        rf_period = rf / 252

        sharpe = (mean_r - rf_period) / std_r
        return -sharpe

def build_lstm_gru_model(timesteps, n_assets):
    """X√¢y d·ª±ng m√¥ h√¨nh LSTM + GRU + Dense(softmax)."""
    model = Sequential()
    model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, n_assets)))
    model.add(GRU(256, return_sequences=False))
    model.add(Dense(n_assets, activation='softmax'))
    return model

def port_char(weights_df, returns_df):
    """
    T√≠nh k·ª≥ v·ªçng l·ª£i nhu·∫≠n (Er) v√† ƒë·ªô l·ªách chu·∫©n (std_dev) c·ªßa danh m·ª•c.
    - weights_df: DataFrame g·ªìm ['Asset','Weight'].
    - returns_df: DataFrame c√°c c·ªôt l√† t√™n Asset, gi√° tr·ªã l√† returns.
    """
    Er_ = returns_df.mean().reset_index()
    Er_.columns = ['Asset','Er']
    weights_merged = pd.merge(weights_df, Er_, on='Asset', how='left')
    weights_merged['Er'].fillna(0, inplace=True)
    portfolio_er = np.dot(weights_merged['Weight'], weights_merged['Er'])
    cov_matrix = returns_df.cov()
    asset_order = weights_merged['Asset']
    cov_matrix = cov_matrix.loc[asset_order, asset_order]
    w = weights_merged['Weight'].values
    portfolio_std_dev = np.sqrt(np.dot(w, np.dot(cov_matrix, w)))
    return portfolio_er, portfolio_std_dev

def sharpe_port(weights_df, returns_df, rf=0.016, freq=252):
    portfolio_er, portfolio_std_dev = port_char(weights_df, returns_df)
    rf_period = rf / freq
    sharpe_ratio_ = (portfolio_er - rf_period) / (portfolio_std_dev + 1e-12)
    return sharpe_ratio_

#========================
# 2) CODE STREAMLIT
#========================

def main():
    st.markdown("""
    ### üß™ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

    ·ª®ng d·ª•ng n√†y c√≥ hai t√πy ch·ªçn d·ªØ li·ªáu ƒë·∫ßu v√†o:

    1. **T·∫£i l√™n file CSV** c√≥ ch·ª©a d·ªØ li·ªáu g·ªìm c√°c c·ªôt `'time'`, `'ticker'`, `'close'`.
    2. **Ho·∫∑c** ƒë·ªÉ h·ªá th·ªëng **t·ª± ƒë·ªông t·∫£i d·ªØ li·ªáu** t·ª´ `vnstock` n·∫øu b·∫°n kh√¥ng upload file.

    üëâ **L∆∞u √Ω:**  
    N·∫øu b·∫°n ch·ªâ mu·ªën **tr·∫£i nghi·ªám nhanh ·ª©ng d·ª•ng**, **KH√îNG c·∫ßn t·∫£i l√™n g√¨ c·∫£**, ch·ªâ c·∫ßn **nh·∫•n n√∫t "Nh·∫•n ƒë·ªÉ b·∫Øt ƒë·∫ßu t√≠nh to√°n"**.  
    H·ªá th·ªëng s·∫Ω s·ª≠ d·ª•ng **m·∫∑c ƒë·ªãnh ng√†nh "X√¢y d·ª±ng"** v√† **kho·∫£ng th·ªùi gian t·ª´ 01/01/2018 ƒë·∫øn 31/12/2024**.  

    """)
    industries = [
        'H√†ng & D·ªãch v·ª• C√¥ng nghi·ªáp',
        'Th·ª±c ph·∫©m v√† ƒë·ªì u·ªëng',
        'ƒêi·ªán, n∆∞·ªõc & xƒÉng d·∫ßu kh√≠ ƒë·ªët',
        'B·∫•t ƒë·ªông s·∫£n',
        'T√†i nguy√™n C∆° b·∫£n',
        'H√†ng c√° nh√¢n & Gia d·ª•ng',
        'H√≥a ch·∫•t',
        'Y t·∫ø',
        'Du l·ªãch v√† Gi·∫£i tr√≠',
        'D·ªãch v·ª• t√†i ch√≠nh',
        'X√¢y d·ª±ng'
    ]

    industry = st.selectbox("Ch·ªçn ng√†nh:", industries, index=industries.index("X√¢y d·ª±ng"))

    
    #========================
    # Nh·∫≠p kho·∫£ng th·ªùi gian
    #========================
    default_start = "2018-01-01"
    default_end   = "2024-12-31"
    default_start_date = datetime.strptime(default_start, '%Y-%m-%d').date()
    default_end_date = datetime.strptime(default_end, '%Y-%m-%d').date()

    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("Ch·ªçn ng√†y b·∫Øt ƒë·∫ßu", value=default_start_date)
    with col2:
        end_date = st.date_input("Ch·ªçn ng√†y k·∫øt th√∫c", value=default_end_date)

    today = datetime.today().date()

    if start_date and end_date:
        if end_date > today:
            st.error("L·ªói: The end date cannot be later than today.")
        else:
            if start_date <= end_date and (end_date - start_date) > timedelta(weeks=4):
                st.success(f"B·∫°n ƒë√£ ch·ªçn d·ªØ li·ªáu t·ª´ {start_date} ƒë·∫øn {end_date}.")
            else:
                st.error("L·ªói: C·∫ßn √≠t nh·∫•t 2 nƒÉm d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")

    # S·ª≠ d·ª•ng gi√° tr·ªã ng√†y d∆∞·ªõi d·∫°ng chu·ªói
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')
    
    
    st.write("**T·∫£i l√™n file CSV (tu·ª≥ ch·ªçn):**")
    uploaded_file = st.file_uploader("Ch·ªçn file CSV (c·∫•u tr√∫c g·ªìm c·ªôt [time, ticker, close])", type=['csv'])

    if st.button("Nh·∫•n ƒë·ªÉ b·∫Øt ƒë·∫ßu t√≠nh to√°n"):
        st.write("**B·∫Øt ƒë·∫ßu l·∫•y d·ªØ li·ªáu & x·ª≠ l√Ω...**")


        #============================
        # B∆Ø·ªöC 1: L·∫§Y D·ªÆ LI·ªÜU
        #============================
        if uploaded_file is not None:
            st.success("ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ file CSV ƒë√£ upload.")
            combined_df = pd.read_csv(uploaded_file)
            required_cols = {'time','ticker','close'}
            if not required_cols.issubset(combined_df.columns):
                st.error("File CSV thi·∫øu c·ªôt b·∫Øt bu·ªôc. C·∫ßn c√≥ [time, ticker, close].")
                return
            combined_df['time'] = pd.to_datetime(combined_df['time'])
            combined_df.sort_values('time', inplace=True)
            combined_df.reset_index(drop=True, inplace=True)
        else:
            st.info("Kh√¥ng upload file CSV => T·∫£i d·ªØ li·ªáu t·ª´ vnstock.")
            stock = Vnstock().stock(symbol='VN30F1M', source='VCI')
            list_icb = stock.listing.symbols_by_industries()
            # L·ªçc danh s√°ch ticker theo t√™n ng√†nh t·ª´ c·ªôt icb_name4 ho·∫∑c icb_name2
            list_ticker = list_icb[(list_icb['icb_name4'] == industry) | (list_icb['icb_name2'] == industry)]['symbol'].to_list()

            list_exchange = stock.listing.symbols_by_exchange()[['symbol','type','exchange']]
            df_filtered = list_exchange[
                list_exchange['symbol'].isin(list_ticker) &
                ((list_exchange['exchange'] == 'HSX') | (list_exchange['exchange'] == 'HNX'))
            ]
            list_ticker = df_filtered['symbol'].to_list()

            all_data = {}
            for ticker in list_ticker:
                df_ = fetch_stock_data(ticker, start_date_str, end_date_str)
                if df_ is not None and not df_.empty:
                    all_data[ticker] = df_
            if len(all_data) == 0:
                st.error("Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu c·ªï phi·∫øu n√†o. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c upload CSV.")
                return
            # G·ªôp t·∫•t c·∫£ DataFrame trong dictionary v·ªÅ m·ªôt DataFrame:
            combined_df = pd.concat(all_data.values(), axis=0).reset_index()
            
        st.write("C√°c c·ªôt c·ªßa DataFrame:", combined_df.columns)
        st.write("D·ªØ li·ªáu c·ªßa combined_df:", combined_df)
        # Chu·∫©n h√≥a t√™n c·ªôt: chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
        combined_df.columns = combined_df.columns.str.lower().str.strip()

        #============================
        # B∆Ø·ªöC 2: X·ª¨ L√ù D·ªÆ LI·ªÜU
        #============================
        try:
            pivot_df = combined_df.pivot(index="time", columns="ticker", values="close")
        except KeyError as e:
            st.error(f"L·ªói khi pivot d·ªØ li·ªáu: {e}. Ki·ªÉm tra l·∫°i t√™n c·ªôt c·ªßa DataFrame.")
            return

        pivot_df.sort_index(inplace=True)
        pivot_df.fillna(0, inplace=True)

        daily_returns = pivot_df.pct_change()
        mean_daily_returns = daily_returns.mean()
        std_daily_returns  = daily_returns.std()
        days_per_year   = 252
        annual_returns  = mean_daily_returns * days_per_year
        annual_volatility = std_daily_returns * np.sqrt(days_per_year)
        sharpe_ratio = annual_returns / annual_volatility

        df_sharpe = pd.DataFrame({
            'annual return': annual_returns,
            'annual volatility': annual_volatility,
            'sharpe ratio': sharpe_ratio
        }).sort_values(by='sharpe ratio', ascending=False)

        # Ki·ªÉm tra n·∫øu s·ªë l∆∞·ª£ng c·ªï phi·∫øu c√≥ t√≠nh Sharpe nh·ªè h∆°n 10
        if df_sharpe.shape[0] < 10:
            st.error("Ng√†nh l·ª±a ch·ªçn kh√¥ng ƒë·ªß 10 c·ªï phi·∫øu c√≥ d·ªØ li·ªáu Sharpe. Vui l√≤ng ch·ªçn ng√†nh kh√°c ho·∫∑c ki·ªÉm tra l·∫°i d·ªØ li·ªáu.")
            return

        st.write("**Top 10 c·ªï phi·∫øu theo Sharpe Ratio**")
        top_10 = df_sharpe.head(10)
        st.dataframe(top_10)

        top_10_symbols = top_10.index.tolist()
        pivot_top10_df = pivot_df[top_10_symbols]

        #============================
        # B∆Ø·ªöC 3: T√ÅCH TRAIN / TEST (theo nƒÉm)
        #============================
        min_year = pivot_top10_df.index.year.min()
        max_year = pivot_top10_df.index.year.max()

        test_year = max_year
        train_years = list(range(min_year, test_year))

        train_price = pivot_top10_df.loc[pivot_top10_df.index.year.isin(train_years)]
        test_price  = pivot_top10_df.loc[pivot_top10_df.index.year == test_year]

        # Reset index
        train_price = train_price.reset_index(drop=True)
        test_price = test_price.reset_index(drop=True)


        #============================
        # B∆Ø·ªöC 4: HU·∫§N LUY·ªÜN M√î H√åNH LSTM-GRU
        #============================
        X_train = train_price.values[np.newaxis, :, :]
        y_train = np.zeros((1, train_price.shape[1]))

        sharpe_model = SharpeLossModel(pd.DataFrame(train_price))
        model_lstm_gru = build_lstm_gru_model(train_price.shape[0], train_price.shape[1])
        model_lstm_gru.compile(optimizer=Adam(), loss=sharpe_model.sharpe_loss)

        st.write("**B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh...**")
        model_lstm_gru.fit(X_train, y_train, epochs=100, batch_size=32, shuffle=False, verbose=1)

        weights_lstm_gru = model_lstm_gru.predict(X_train)[0]
        results_LSTM_GRU = pd.DataFrame({'Asset': top_10_symbols, "Weight": weights_lstm_gru})

        st.write("**Ph√¢n b·ªï danh m·ª•c t·ª´ m√¥ h√¨nh LSTM-GRU:**")
        # Chuy·ªÉn ƒë·ªïi tr·ªçng s·ªë th√†nh % v√† l√†m tr√≤n
        results_LSTM_GRU['Weight (%)'] = (results_LSTM_GRU['Weight'] * 100).round(2).astype(str) + "%"
        st.dataframe(results_LSTM_GRU[['Asset', 'Weight (%)']].sort_values('Weight (%)', ascending=False))

        st.success("Ho√†n t·∫•t qu√° tr√¨nh t√≠nh to√°n.")


if __name__ == '__main__':
    main()
