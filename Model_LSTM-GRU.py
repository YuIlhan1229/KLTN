import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import squarify
import random
import base64
from datetime import datetime, timedelta

from tensorflow.keras import backend as K
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU
from tensorflow.keras.optimizers import Adam
from vnstock import Vnstock

st.set_page_config(
    page_title="Applying deep learning to portfolio optimization in the Vietnamese stock market", 
    page_icon="üìä"
)

# V√¨ Streamlit d√πng c∆° ch·∫ø v·∫Ω inline, ta import pyplot ·ªü ch·∫ø ƒë·ªô "inline"
plt.switch_backend('Agg')

#========================
# 0) (Tu·ª≥ ch·ªçn) C·ªë ƒë·ªãnh random seed ƒë·ªÉ so s√°nh ch·∫∑t h∆°n
#========================
SEED_VALUE = 42
random.seed(SEED_VALUE)
np.random.seed(SEED_VALUE)
tf.random.set_seed(SEED_VALUE)

#========================
# T·∫Øt c·∫£nh b√°o
#========================
import warnings
warnings.filterwarnings('ignore')

#========================
# 1) ƒê·ªäNH NGHƒ®A C√ÅC H√ÄM, M√î H√åNH
#========================

def add_bg_from_local(image_file):
    with open(image_file, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read())
    st.markdown(
    f"""
    <style>
    .stApp {{
        background-image: url(data:image/{"png"};base64,{encoded_string.decode()});
        background-size: cover;
        background-color: rgba(255, 255, 255, 0.7);
        background-blend-mode: overlay;
    }}
    .custom-title {{
        color: #F05454;
    }}
    .stMarkdown, .stText {{
        color: #30475E !important;
    }}
    </style>
    """,
    unsafe_allow_html=True
    )

add_bg_from_local('background.png')

#========================
# Hi·ªÉn th·ªã logo v√† ti√™u ƒë·ªÅ
#========================
# Chia layout th√†nh 2 c·ªôt:
#  - col_logo: c·ªôt ƒë·ªÉ ƒë·∫∑t logo
#  - col_title: c·ªôt ƒë·ªÉ ƒë·∫∑t ti√™u ƒë·ªÅ
# T·ª∑ l·ªá [1, 4] nghƒ©a l√† c·ªôt logo chi·∫øm 1 ph·∫ßn, c·ªôt ti√™u ƒë·ªÅ chi·∫øm 4 ph·∫ßn.
col_logo, col_title = st.columns([1, 4])

with col_logo:
    # Hi·ªÉn th·ªã logo, c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh 'width' ƒë·ªÉ tƒÉng/gi·∫£m k√≠ch th∆∞·ªõc ·∫£nh
    st.image("Logo_HUB.png", width=400)

with col_title:
    # Ti√™u ƒë·ªÅ ƒë∆∞·ª£c cƒÉn gi·ªØa v·ªõi CSS, ti√™u ƒë·ªÅ 1 v√† ti√™u ƒë·ªÅ 2 ƒë·ªôc l·∫≠p, c√≥ k√≠ch th∆∞·ªõc ch·ªØ kh√°c nhau
    st.markdown(
        """
        <div style="text-align: center;">
            <h1 style="margin-bottom: 0px; color: #0B5394; font-size: 32px;">TR∆Ø·ªúNG ƒê·∫†I H·ªåC NG√ÇN H√ÄNG TH√ÄNH PH·ªê H·ªí CH√ç MINH</h1>
            <h2 style="margin-top: 5px; color: #333; font-size: 36px;">X√¢y d·ª±ng danh m·ª•c ƒë·∫ßu t∆∞ t·ªëi ∆∞u b·∫±ng m√¥ h√¨nh LSTM - GRU</h2>
        </div>
        """,
        unsafe_allow_html=True
    )


#========================
# C√°c h√†m l·∫•y d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh
#========================

def fetch_stock_data(ticker, start_date, end_date):
    """T·∫£i d·ªØ li·ªáu gi√° ƒë√≥ng c·ª≠a, tr·∫£ v·ªÅ DataFrame g·ªìm c·ªôt 'close' v√† index='time'."""
    try:
        dt = Vnstock().stock(symbol=ticker, source='VCI').quote.history(
            start=start_date, 
            end=end_date
        )
        dt['time'] = pd.to_datetime(dt['time'])
        dt.set_index('time', inplace=True)
        dt = dt[['close']].copy()
        dt['ticker'] = ticker
        return dt
    except:
        return None

class SharpeLossModel:
    def __init__(self, data):
        # data shape (T, 10)
        self.data = tf.constant(data.values, dtype=tf.float32)

    def sharpe_loss(self, _, y_pred):
        """M·∫•t m√°t = -Sharpe => m√¥ h√¨nh c·ª±c ƒë·∫°i ho√° Sharpe."""
        data_normalized = self.data / (self.data[0] + K.epsilon())
        portfolio_values = tf.reduce_sum(data_normalized * y_pred[0], axis=1)
        pvals_shift = portfolio_values[:-1]
        pvals_curr  = portfolio_values[1:]
        daily_ret = (pvals_curr - pvals_shift) / (pvals_shift + K.epsilon())

        mean_r = K.mean(daily_ret)
        std_r  = K.std(daily_ret) + K.epsilon()

        rf = 0.016
        rf_period = rf / 252

        sharpe = (mean_r - rf_period) / std_r
        return -sharpe

def build_lstm_gru_model(timesteps, n_assets):
    """X√¢y d·ª±ng m√¥ h√¨nh LSTM + GRU + Dense(softmax)."""
    model = Sequential()
    model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, n_assets)))
    model.add(GRU(256, return_sequences=False))
    model.add(Dense(n_assets, activation='softmax'))
    return model

def port_char(weights_df, returns_df):
    Er_ = returns_df.mean().reset_index()
    Er_.columns = ['Asset','Er']
    weights_merged = pd.merge(weights_df, Er_, on='Asset', how='left')
    weights_merged['Er'].fillna(0, inplace=True)
    portfolio_er = np.dot(weights_merged['Weight'], weights_merged['Er'])
    cov_matrix = returns_df.cov()
    asset_order = weights_merged['Asset']
    cov_matrix = cov_matrix.loc[asset_order, asset_order]
    w = weights_merged['Weight'].values
    portfolio_std_dev = np.sqrt(np.dot(w, np.dot(cov_matrix, w)))
    return portfolio_er, portfolio_std_dev

def sharpe_port(weights_df, returns_df, rf=0.016, freq=252):
    portfolio_er, portfolio_std_dev = port_char(weights_df, returns_df)
    rf_period = rf / freq
    sharpe_ratio_ = (portfolio_er - rf_period) / (portfolio_std_dev + 1e-12)
    return sharpe_ratio_

#========================
# 2) CODE STREAMLIT
#========================

def main():
    st.markdown("""
    ·ª®ng d·ª•ng n√†y c√≥ hai t√πy ch·ªçn:
    1. T·∫£i l√™n file CSV c√≥ d·ªØ li·ªáu 'time', 'ticker', 'close'.
    2. T·ª± ƒë·ªông t·∫£i d·ªØ li·ªáu t·ª´ `vnstock` (n·∫øu kh√¥ng upload).
    Sau ƒë√≥, h·ªá th·ªëng t·ª± ƒë·ªông t√≠nh Sharpe Ratio, ch·ªçn Top 10 c·ªï phi·∫øu, hu·∫•n luy·ªán LSTM-GRU.
    """)

    industry = st.selectbox("Ch·ªçn ng√†nh:", ["X√¢y d·ª±ng"], index=0)
    
    #========================
    # Nh·∫≠p kho·∫£ng th·ªùi gian
    #========================
    default_start = "2018-01-01"
    default_end   = "2024-12-31"
    # Chuy·ªÉn ƒë·ªïi chu·ªói sang date object
    default_start_date = datetime.strptime(default_start, '%Y-%m-%d').date()
    default_end_date = datetime.strptime(default_end, '%Y-%m-%d').date()

    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input(":red[Choose start date]", value=default_start_date)
    with col2:
        end_date = st.date_input(":red[Choose end date]", value=default_end_date)

    today = datetime.today().date()

    if start_date and end_date:
        if end_date > today:
            st.error("L·ªói: The end date cannot be later than today.")
        elif start_date <= end_date and (end_date - start_date) > timedelta(weeks=4):
            st.success(f"You have chosen the period from {start_date} to {end_date}")
        else:
            st.error("L·ªói: The end date must be after the start date, and the period must be sufficiently long.")
    
    # N·∫øu ng∆∞·ªùi d√πng kh√¥ng thay ƒë·ªïi ng√†y (v·∫´n m·∫∑c ƒë·ªãnh)
    if start_date == default_start_date and end_date == default_end_date:
        st.info(f"Default date range selected: {default_start} to {default_end}")

    # S·ª≠ d·ª•ng gi√° tr·ªã ng√†y d∆∞·ªõi d·∫°ng chu·ªói
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')
    
    st.write(f"**D·ªØ li·ªáu t·ª´ {start_date_str} ƒë·∫øn {end_date_str}**")
    
    st.write("**T·∫£i l√™n file CSV (tu·ª≥ ch·ªçn):**")
    uploaded_file = st.file_uploader("Ch·ªçn file CSV (c·∫•u tr√∫c g·ªìm c·ªôt [time, ticker, close])", type=['csv'])

    if st.button("Nh·∫•n ƒë·ªÉ b·∫Øt ƒë·∫ßu t√≠nh to√°n"):
        st.write("**B·∫Øt ƒë·∫ßu l·∫•y d·ªØ li·ªáu & x·ª≠ l√Ω...**")

        #============================
        # B∆Ø·ªöC 1: L·∫§Y D·ªÆ LI·ªÜU
        #============================
        if uploaded_file is not None:
            st.success("ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ file CSV ƒë√£ upload.")
            combined_df = pd.read_csv(uploaded_file)
            required_cols = {'time','ticker','close'}
            if not required_cols.issubset(combined_df.columns):
                st.error("File CSV thi·∫øu c·ªôt b·∫Øt bu·ªôc. C·∫ßn c√≥ [time, ticker, close].")
                return
            combined_df['time'] = pd.to_datetime(combined_df['time'])
            combined_df.sort_values('time', inplace=True)
            combined_df.reset_index(drop=True, inplace=True)
        else:
            st.info("Kh√¥ng upload file CSV => T·∫£i d·ªØ li·ªáu t·ª´ vnstock.")
            stock = Vnstock().stock(symbol='VN30F1M', source='VCI')
            list_icb = stock.listing.symbols_by_industries()
            list_ticker = list_icb[list_icb['icb_name4'] == industry]['symbol'].to_list()

            list_exchange = stock.listing.symbols_by_exchange()[['symbol','type','exchange']]
            df_filtered = list_exchange[
                list_exchange['symbol'].isin(list_ticker) &
                ((list_exchange['exchange'] == 'HSX') | (list_exchange['exchange'] == 'HNX'))
            ]
            list_ticker = df_filtered['symbol'].to_list()

            all_data = {}
            for ticker in list_ticker:
                df_ = fetch_stock_data(ticker, start_date_str, end_date_str)
                if df_ is not None and not df_.empty:
                    all_data[ticker] = df_
            if len(all_data) == 0:
                st.error("Kh√¥ng t·∫£i ƒë∆∞·ª£c d·ªØ li·ªáu c·ªï phi·∫øu n√†o. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c upload CSV.")
                return
            combined_df = pd.concat(all_data.values(), axis=0).reset_index(drop=True)

        st.write("**C·∫•u tr√∫c d·ªØ li·ªáu:**")
        st.dataframe(combined_df)

        #============================
        # B∆Ø·ªöC 2: X·ª¨ L√ù D·ªÆ LI·ªÜU
        #============================
        pivot_df = combined_df.pivot(index="time", columns="ticker", values="close")
        pivot_df.sort_index(inplace=True)
        pivot_df.fillna(0, inplace=True)

        daily_returns = pivot_df.pct_change()
        mean_daily_returns = daily_returns.mean()
        std_daily_returns  = daily_returns.std()
        days_per_year   = 252
        annual_returns  = mean_daily_returns * days_per_year
        annual_volatility = std_daily_returns * np.sqrt(days_per_year)
        sharpe_ratio = annual_returns / annual_volatility

        df_sharpe = pd.DataFrame({
            'Annual Return': annual_returns,
            'Annual Volatility': annual_volatility,
            'Sharpe Ratio': sharpe_ratio
        }).sort_values(by='Sharpe Ratio', ascending=False)

        st.write("**Top 10 c·ªï phi·∫øu theo Sharpe Ratio**")
        top_10 = df_sharpe.head(10)
        st.dataframe(top_10)

        top_10_symbols = top_10.index.tolist()
        pivot_top10_df = pivot_df[top_10_symbols]

        #============================
        # B∆Ø·ªöC 3: T√ÅCH TRAIN / TEST
        #============================
        train_price = pivot_top10_df.loc[pivot_top10_df.index.year < 2024]
        test_price  = pivot_top10_df.loc[pivot_top10_df.index.year == 2024]

        train_price = train_price.reset_index(drop=True)
        test_price = test_price.reset_index(drop=True)

        #============================
        # B∆Ø·ªöC 4: HU·∫§N LUY·ªÜN M√î H√åNH LSTM-GRU
        #============================
        X_train = train_price.values[np.newaxis, :, :]
        y_train = np.zeros((1, train_price.shape[1]))

        sharpe_model = SharpeLossModel(pd.DataFrame(train_price))
        model_lstm_gru = build_lstm_gru_model(train_price.shape[0], train_price.shape[1])
        model_lstm_gru.compile(optimizer=Adam(), loss=sharpe_model.sharpe_loss)

        st.write("**B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh...** (epochs=100, batch_size=32)")
        model_lstm_gru.fit(X_train, y_train, epochs=100, batch_size=32, shuffle=False, verbose=1)

        weights_lstm_gru = model_lstm_gru.predict(X_train)[0]
        results_LSTM_GRU = pd.DataFrame({'Asset': top_10_symbols, "Weight": weights_lstm_gru})

        st.write("**Ph√¢n b·ªï danh m·ª•c t·ª´ m√¥ h√¨nh LSTM-GRU:**")
        st.dataframe(results_LSTM_GRU.sort_values('Weight', ascending=False))

        fig, ax = plt.subplots(figsize=(12, 6))
        sorted_df = results_LSTM_GRU.sort_values('Weight', ascending=False)
        ax.bar(sorted_df['Asset'], sorted_df['Weight'], color='green')
        ax.set_xlabel('T√†i s·∫£n')
        ax.set_ylabel('Tr·ªçng s·ªë')
        ax.set_title('Ph√¢n b·ªï t√†i s·∫£n (LSTM-GRU)')
        plt.xticks(rotation=0)
        st.pyplot(fig)

        #============================
        # B∆Ø·ªöC 5: T√çNH TO√ÅN V√Ä SO S√ÅNH V·ªöI 2 PH∆Ø∆†NG PH√ÅP
        #============================
        st.write("**So s√°nh v·ªõi 2 ph∆∞∆°ng ph√°p: Ph√¢n b·ªï ƒë·ªìng ƒë·ªÅu & 80-20**")

        # Ph√¢n b·ªï ƒë·ªìng ƒë·ªÅu
        Allo_1 = pd.DataFrame({'Asset': top_10_symbols, 'Weight': [1/len(top_10_symbols)]*len(top_10_symbols)})

        # Chi·∫øn l∆∞·ª£c 80-20
        mcp = train_price.columns
        Allo_2_temp = train_price.sum().sort_values(ascending=False).reset_index()
        Allo_2_temp.columns = ['Asset','Er']
        top_count = int(0.2 * len(mcp))
        bottom_count = len(mcp) - top_count
        top_weights = [0.8 / top_count] * top_count
        bottom_weights = [0.2 / bottom_count] * bottom_count
        Allo_2_temp['Weight'] = top_weights + bottom_weights
        Allo_2 = Allo_2_temp[['Asset','Weight']]

        Er_lstm_gru, std_lstm_gru = port_char(results_LSTM_GRU, test_price)
        Er_1, std_1 = port_char(Allo_1, test_price)
        Er_2, std_2 = port_char(Allo_2, test_price)

        shr_lstm_gru = sharpe_port(results_LSTM_GRU, test_price)
        shr_1 = sharpe_port(Allo_1, test_price)
        shr_2 = sharpe_port(Allo_2, test_price)

        table_ = pd.DataFrame({
            'Expected_return': [Er_lstm_gru, Er_1, Er_2],
            'Standard_deviation': [std_lstm_gru, std_1, std_2],
            'Sharpe_ratio': [shr_lstm_gru, shr_1, shr_2]
        }, index=['LSTM_GRU','Ph√¢n b·ªï ƒë·ªÅu','80-20'])

        st.write("**B·∫£ng so s√°nh danh m·ª•c tr√™n Test set**")
        st.dataframe(table_.T)

        fig3, ax3 = plt.subplots(figsize=(8, 4))
        categories = table_.columns.values
        er_vals = table_['Expected_return'].values
        std_vals = table_['Standard_deviation'].values
        shr_vals = table_['Sharpe_ratio'].values

        x_ = np.arange(len(categories))
        w_ = 0.2

        ax3.bar(x_ - w_, er_vals, w_, label='Expected_return')
        ax3.bar(x_, std_vals, w_, label='Standard_deviation')
        ax3.bar(x_ + w_, shr_vals, w_, label='Sharpe_ratio', color='green')

        ax3.set_xticks(x_)
        ax3.set_xticklabels(categories)
        ax3.set_ylabel("Gi√° tr·ªã")
        ax3.legend()
        ax3.set_title("So s√°nh Er, Std_dev, Sharpe (Test set)")

        st.pyplot(fig3)
        st.success("Ho√†n t·∫•t qu√° tr√¨nh t√≠nh to√°n & tr·ª±c quan (c√≥ t√≠nh nƒÉng upload CSV).")

if __name__ == '__main__':
    main()
